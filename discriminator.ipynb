{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import librosa\n",
    "import IPython\n",
    "import data_loader\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pformat\n",
    "import logging\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from functools import partial\n",
    "keras = tf.keras\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "importlib.reload(data_loader)\n",
    "DataLoader = data_loader.DataLoader\n",
    "load_config = data_loader.load_config\n",
    "logger = data_loader.logger\n",
    "\n",
    "config = './config/hub2-6.json'\n",
    "data = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import *\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "BatchNorm = keras.layers.BatchNormalization\n",
    "Conv2D = keras.layers.Conv2D\n",
    "DConv = keras.layers.Conv2DTranspose\n",
    "Dense = keras.layers.Dense\n",
    "\n",
    "\n",
    "def _get_embedding_table(checkpoint_file):\n",
    "    ckpt_loader = tf.train.load_checkpoint(checkpoint_file)\n",
    "    #     model = keras_bert.load_trained_model_from_checkpoint(config_file=config_file,\n",
    "    #                                                          checkpoint_file=checkpoint_file,\n",
    "    #                                                          training=False,\n",
    "    #                                                          trainable=None,\n",
    "    #                                                          output_layer_num=1,\n",
    "    #                                                          seq_len=dl.max_len)\n",
    "    #     embed_table = keras_bert.get_token_embedding(model)\n",
    "    #     del(model)\n",
    "    embed_table = ckpt_loader.get_tensor('bert/embeddings/word_embeddings')\n",
    "    del (ckpt_loader)\n",
    "    return embed_table\n",
    "\n",
    "\n",
    "class Generator(keras.models.Model):\n",
    "    def __init__(self, config, checkpoint_file, input_shape, **kwargs):\n",
    "        super(Generator, self).__init__(**kwargs)\n",
    "        self.config = load_config(config)\n",
    "        self.audio_shape = input_shape\n",
    "\n",
    "        self.act_fn = keras.layers.LeakyReLU()\n",
    "        self.kernel_size = self.config['kernel_size']\n",
    "\n",
    "        self.embedding_table = _get_embedding_table(checkpoint_file)\n",
    "\n",
    "        self.conv = [\n",
    "            Conv2D(filters=32, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None,\n",
    "                   input_shape=input_shape),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=64, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=128, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=256, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=512, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            #             keras.layers.Flatten(),\n",
    "            #             Dense(units=output_size, activation=None),\n",
    "            #             self.act_fn\n",
    "        ]\n",
    "\n",
    "        self.dconv = [\n",
    "            # 16\n",
    "            DConv(filters=512, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            # 32\n",
    "            DConv(filters=256, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            # 64\n",
    "            DConv(filters=128, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "\n",
    "            DConv(filters=64, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "\n",
    "            DConv(filters=1, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            keras.layers.ReLU(max_value=80.0)\n",
    "        ]\n",
    "        self.embed_hidden = Dense(units=self.hidden_size[0] * self.hidden_size[1])\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, **kwargs):\n",
    "        audio, text = inputs\n",
    "        audio = tf.expand_dims(audio, -1)\n",
    "\n",
    "        for layer in self.conv:\n",
    "            audio = layer(audio)\n",
    "\n",
    "        audio = self._concat_text(audio, text)\n",
    "        for layer in self.dconv:\n",
    "            audio = layer(audio)\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "        return audio\n",
    "\n",
    "    @property\n",
    "    def hidden_size(self):\n",
    "        return int(self.audio_shape[0] / 2 ** 5), int(self.audio_shape[1] / 2 ** 5)\n",
    "\n",
    "    def _concat_text(self, audio, text):\n",
    "        text = tf.gather(self.embedding_table, text)\n",
    "        text = self.embed_hidden(text)\n",
    "        text = tf.reshape(text, shape=[-1, 32, *self.hidden_size]) \n",
    "        text = tf.transpose(text, perm=[0, 2, 3, 1])\n",
    "        audio = tf.concat([audio, text], axis=-1)\n",
    "        return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout = keras.layers.Dropout\n",
    "\n",
    "class Discriminator(keras.models.Model):\n",
    "    def __init__(self, config, input_shape, checkpoint_file):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.config = load_config(config)\n",
    "        self.audio_shape = input_shape\n",
    "        \n",
    "        self.rate = 0.3\n",
    "        self.alpha = 0.3\n",
    "        self.kernel_size = self.config['kernel_size']\n",
    "        self.max_len = self.config['max_len']\n",
    "        self.batch_size = self.config['batch_size']\n",
    "        \n",
    "        self.act_fn = keras.layers.LeakyReLU(alpha=self.alpha)\n",
    "        self.embedding_table = _get_embedding_table(checkpoint_file)\n",
    "        \n",
    "        self.conv = [\n",
    "            Conv2D(filters=32, kernel_size=self.kernel_size, padding='same', strides=(2, 2), activation=None),\n",
    "            Dropout(rate=self.rate),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=64, kernel_size=self.kernel_size, padding='same', strides=(2, 2), activation=None),\n",
    "            Dropout(rate=self.rate),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=128, kernel_size=self.kernel_size, padding='same', strides=(2, 2), activation=None),\n",
    "            Dropout(rate=self.rate),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=256, kernel_size=self.kernel_size, padding='same', strides=(2, 2), activation=None),\n",
    "            Dropout(rate=self.rate),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=512, kernel_size=self.kernel_size, padding='same', strides=(2, 2), activation=None),\n",
    "            Dropout(rate=self.rate),\n",
    "            self.act_fn,\n",
    "            keras.layers.Flatten()\n",
    "        ]\n",
    "        self.prob = [\n",
    "            Dense(units=512, activation=None),\n",
    "            Dropout(rate=self.rate),\n",
    "            self.act_fn,\n",
    "            Dense(units=1, activation=None),\n",
    "            keras.layers.Activation('sigmoid')\n",
    "        ]\n",
    "        self.embed_hidden = Dense(units=self.hidden_size[0] * self.hidden_size[1])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        audio, text = inputs\n",
    "        audio = tf.expand_dims(audio, -1)\n",
    "        \n",
    "        for layer in self.conv:\n",
    "            audio = layer(audio)\n",
    "        \n",
    "        audio = self._concat_text(audio, text)\n",
    "        \n",
    "        for layer in self.prob:\n",
    "            audio = layer(audio)\n",
    "            \n",
    "        prob = audio\n",
    "        return prob\n",
    "\n",
    "    @property\n",
    "    def hidden_size(self):\n",
    "        return int(self.audio_shape[0] / 2 ** 5), int(self.audio_shape[1] / 2 ** 5)\n",
    "\n",
    "    def _concat_text(self, audio, text):\n",
    "        text = tf.gather(self.embedding_table, text)\n",
    "        text = self.embed_hidden(text)\n",
    "        text = tf.reshape(text, shape=[-1, self.max_len * self.hidden_size[0] * self.hidden_size[1]])\n",
    "#         text = tf.transpose(text, perm=[0, 2, 3, 1])\n",
    "        audio = tf.concat([audio, text], axis=-1)\n",
    "        return audio\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DataLoader initializing\n",
      "INFO:root:reading lab data from ../data/soundAttGAN & ../data/soundAttGAN/koreancorpus.xlsx\n",
      "INFO:root:total number of data: 1925\n",
      "INFO:root:reading hub data from ../data/KsponSpeech_01\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0094\n",
      "INFO:root:total number of data: 709\n",
      "INFO:root:Reading vocab from ../data/bert_model/vocab.txt\n",
      "INFO:root:The number of vocab is 119547\n",
      "INFO:root:Build done\n",
      "INFO:root:{'batch_size': 32,\n",
      " 'epochs': 100,\n",
      " 'fmax': 8000,\n",
      " 'hop_length': 250,\n",
      " 'kernel_size': 4,\n",
      " 'learning_rate': 0.001,\n",
      " 'max_len': 32,\n",
      " 'max_sec': 4,\n",
      " 'n_fft': 510,\n",
      " 'n_max': 100000,\n",
      " 'n_mels': 128,\n",
      " 'output_size': 256,\n",
      " 'sr_hub': 16000,\n",
      " 'sr_lab': 22050,\n",
      " 'top_db': 80.0,\n",
      " 'win_length': 510,\n",
      " 'window': 'hann'}\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(config=config, data=data, n_max=None, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(config, checkpoint_file='../data/bert_model/bert_model.ckpt', input_shape=dl.stft_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = Discriminator(config, input_shape=dl.stft_shape, checkpoint_file='../data/bert_model/bert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_audio = tf.data.Dataset.from_generator(partial(dl.train_generator, data='hub', mel_spectrogram=False, return_text=False), output_types=tf.float32)\n",
    "dataset_text = tf.data.Dataset.from_generator(partial(dl.train_generator, data='hub', mel_spectrogram=False, return_text=True), output_types=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.zip((dataset_audio, dataset_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.shuffle(dl.batch_size * 10).batch(dl.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2526, shape=(32, 256, 256), dtype=float32, numpy=\n",
       "array([[[1.39921931e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 7.71267241e-06, 0.00000000e+00],\n",
       "        [1.51802742e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 5.59967120e-05, 1.79467424e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.12263697e-05, ...,\n",
       "         5.15093489e-05, 7.99545160e-05, 4.10088796e-05],\n",
       "        [1.77646580e-05, 0.00000000e+00, 5.23445742e-05, ...,\n",
       "         6.01097308e-05, 5.87052018e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 2.73262822e-06, 1.83947350e-06, ...,\n",
       "         0.00000000e+00, 2.71991084e-05, 1.06825673e-05]],\n",
       "\n",
       "       [[2.71961835e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.78677559e-04, ...,\n",
       "         0.00000000e+00, 4.93545376e-05, 2.19450558e-05],\n",
       "        [2.43652339e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.03583352e-05, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 4.03664235e-05, 0.00000000e+00, ...,\n",
       "         7.00128930e-06, 2.42688402e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.48791694e-05, 4.01838333e-05, 2.06750665e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.07800506e-05, ...,\n",
       "         0.00000000e+00, 1.80088828e-05, 6.93458014e-06]],\n",
       "\n",
       "       [[7.77254318e-05, 1.71621177e-05, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.87831210e-05, 0.00000000e+00],\n",
       "        [4.00509089e-06, 0.00000000e+00, 5.71696786e-04, ...,\n",
       "         2.09912978e-05, 1.21371368e-05, 2.54094830e-05],\n",
       "        [8.25697643e-05, 3.69600893e-05, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 9.62900958e-06, 2.08001038e-05],\n",
       "        ...,\n",
       "        [0.00000000e+00, 4.96832399e-05, 0.00000000e+00, ...,\n",
       "         2.43158356e-05, 1.01893755e-04, 0.00000000e+00],\n",
       "        [1.88931681e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         6.87487627e-05, 6.94872942e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 9.59303998e-06, 1.83100710e-05, ...,\n",
       "         0.00000000e+00, 1.63783625e-05, 1.00018478e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.64251716e-07, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 6.67274617e-06, 0.00000000e+00],\n",
       "        [1.65721231e-05, 0.00000000e+00, 8.53560632e-05, ...,\n",
       "         1.09214143e-05, 1.03088532e-04, 1.47544979e-05],\n",
       "        [4.63392962e-06, 8.90479569e-05, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 3.50055489e-05, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 3.46115594e-05, 1.30373628e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         8.83818029e-06, 8.62819579e-05, 1.03898708e-06],\n",
       "        [0.00000000e+00, 5.09341589e-07, 0.00000000e+00, ...,\n",
       "         8.36554136e-07, 0.00000000e+00, 1.23756636e-05]],\n",
       "\n",
       "       [[3.42122657e-05, 7.64507149e-07, 3.96732285e-05, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.35077920e-04, ...,\n",
       "         0.00000000e+00, 1.02825237e-04, 7.88864145e-06],\n",
       "        [3.03956040e-06, 1.47493120e-04, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 3.05931680e-05, ...,\n",
       "         6.04069828e-06, 1.13896560e-04, 3.11595795e-05],\n",
       "        [3.51324707e-05, 0.00000000e+00, 6.92140820e-05, ...,\n",
       "         1.33583671e-04, 7.92708015e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.17096624e-06, 2.13013791e-05, 7.36181937e-06]],\n",
       "\n",
       "       [[1.99423471e-06, 1.47365936e-05, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.46497832e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.25899369e-05, ...,\n",
       "         0.00000000e+00, 3.72923678e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 9.20271996e-05, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 4.07961488e-05, 2.02142883e-06],\n",
       "        ...,\n",
       "        [0.00000000e+00, 3.68514266e-05, 3.30266812e-06, ...,\n",
       "         0.00000000e+00, 1.18730241e-04, 1.63139339e-06],\n",
       "        [3.11331746e-06, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.37643938e-05, 5.73385114e-05, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.65976016e-05, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 9.27352357e-06]]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1183, shape=(32, 1), dtype=float32, numpy=\n",
       "array([[0.48482022],\n",
       "       [0.49880293],\n",
       "       [0.5037859 ],\n",
       "       [0.48213038],\n",
       "       [0.50407374],\n",
       "       [0.50232714],\n",
       "       [0.5029826 ],\n",
       "       [0.51282233],\n",
       "       [0.48933384],\n",
       "       [0.49239397],\n",
       "       [0.514345  ],\n",
       "       [0.49680606],\n",
       "       [0.5002267 ],\n",
       "       [0.4990236 ],\n",
       "       [0.49451622],\n",
       "       [0.49072638],\n",
       "       [0.49933955],\n",
       "       [0.48556334],\n",
       "       [0.49817875],\n",
       "       [0.50264186],\n",
       "       [0.4944388 ],\n",
       "       [0.49623784],\n",
       "       [0.49426922],\n",
       "       [0.47884423],\n",
       "       [0.50393474],\n",
       "       [0.5085898 ],\n",
       "       [0.4965487 ],\n",
       "       [0.49466863],\n",
       "       [0.50327194],\n",
       "       [0.49697104],\n",
       "       [0.49931967],\n",
       "       [0.50034785]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "leaky_re_lu_8 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           multiple                  544       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           multiple                  32832     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           multiple                  131200    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           multiple                  524544    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           multiple                  2097664   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  17826304  \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  513       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             multiple                  49216     \n",
      "=================================================================\n",
      "Total params: 20,662,817\n",
      "Trainable params: 20,662,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  544       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  2097664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  4456960   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr multiple                  2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr multiple                  524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr multiple                  1025      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  49216     \n",
      "=================================================================\n",
      "Total params: 10,054,753\n",
      "Trainable params: 10,050,849\n",
      "Non-trainable params: 3,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_d(real, fake):\n",
    "    loss_real = keras.losses.binary_crossentropy(tf.ones_like(real), real)\n",
    "    loss_fake = keras.losses.binary_crossentropy(tf.zeros_like(fake), fake)\n",
    "    loss = loss_real + loss_fake\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def loss_g(fake):\n",
    "    loss = keras.losses.binary_crossentropy(tf.ones_like(fake), fake)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = dis(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2746, shape=(), dtype=float32, numpy=1.3865641>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_d(prob, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2773, shape=(), dtype=float32, numpy=0.698141>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_g(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
