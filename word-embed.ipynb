{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_bert\n",
    "from functools import partial\n",
    "import importlib\n",
    "import data_loader\n",
    "importlib.reload(data_loader)\n",
    "\n",
    "DataLoader = data_loader.DataLoader\n",
    "\n",
    "# keras_bert.backend.TF_KERAS = 1\n",
    "\n",
    "config = './config/hub2-1.json'\n",
    "print(keras_bert.backend.TF_KERAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DataLoader initializing\n",
      "INFO:root:reading lab data from ../data/soundAttGAN & ../data/soundAttGAN/koreancorpus.xlsx\n",
      "INFO:root:total number of data: 1925\n",
      "INFO:root:reading hub data from ../data/KsponSpeech_01\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0094\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0090\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0048\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0016\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0020\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0074\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0093\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0001\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0105\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0052\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0017\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0039\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0076\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0031\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0087\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0082\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0037\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0019\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0067\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0072\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0006\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0117\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0085\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0029\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0083\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0010\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0116\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0056\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0075\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0043\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0119\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0044\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0115\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0071\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0003\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0004\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0011\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0062\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0103\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0005\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0045\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0014\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0108\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0079\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0032\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0057\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0122\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0092\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0120\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0102\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0050\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0081\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0089\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0007\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0038\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0113\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0018\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0088\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0022\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0033\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0068\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0073\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0034\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0099\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0107\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0065\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0041\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0040\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0078\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0021\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0030\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0064\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0100\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0013\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0053\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0104\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0111\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0028\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0091\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0025\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0109\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0098\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0023\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0012\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0042\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0084\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0058\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0110\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0101\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0106\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0024\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0046\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0047\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0063\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0123\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0059\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0054\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0055\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0051\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0015\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0009\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0095\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0002\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0096\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0061\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0069\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0060\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0124\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0121\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0097\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0080\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0035\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0008\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0026\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0027\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0066\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0077\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0112\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0049\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0036\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0070\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0086\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0118\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0114\n",
      "INFO:root:total number of data: 124000\n",
      "INFO:root:Reading vocab from ../data/bert_model/vocab.txt\n",
      "INFO:root:The number of vocab is 119547\n",
      "INFO:root:Build done\n",
      "INFO:root:{'batch_size': 256,\n",
      " 'epochs': 10000,\n",
      " 'fmax': 8000,\n",
      " 'hop_length': 250,\n",
      " 'kernel_size': 4,\n",
      " 'learning_rate': 0.001,\n",
      " 'max_len': 32,\n",
      " 'max_sec': 2,\n",
      " 'n_fft': 510,\n",
      " 'n_max': 100000,\n",
      " 'n_mels': 128,\n",
      " 'output_size': 256,\n",
      " 'sr_hub': 16000,\n",
      " 'sr_lab': 22050,\n",
      " 'top_db': 80.0,\n",
      " 'win_length': 510,\n",
      " 'window': 'hann'}\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(config=config, data='../data', n_max=None)\n",
    "config_file = os.path.join(dl.data, 'bert_model', 'bert_config.json')\n",
    "checkpoint_file = os.path.join(dl.data, 'bert_model', 'bert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dl.train_generator(data='hub', return_text=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 8924,\n",
       " 31401,\n",
       " 25503,\n",
       " 118671,\n",
       " 9682,\n",
       " 9539,\n",
       " 18784,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_embedding_table():\n",
    "    ckpt_loader = tf.train.load_checkpoint(checkpoint_file)\n",
    "#     model = keras_bert.load_trained_model_from_checkpoint(config_file=config_file,\n",
    "#                                                          checkpoint_file=checkpoint_file,\n",
    "#                                                          training=False,\n",
    "#                                                          trainable=None,\n",
    "#                                                          output_layer_num=1,\n",
    "#                                                          seq_len=dl.max_len)\n",
    "#     embed_table = keras_bert.get_token_embedding(model)\n",
    "#     del(model)\n",
    "    embed_table = ckpt_loader.get_tensor('bert/embeddings/word_embeddings')\n",
    "    return embed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import *\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "BatchNorm = keras.layers.BatchNormalization\n",
    "Conv2D = keras.layers.Conv2D\n",
    "DConv = keras.layers.Conv2DTranspose\n",
    "Dense = keras.layers.Dense\n",
    "\n",
    "\n",
    "class AutoEncoder(keras.models.Model):\n",
    "    def __init__(self, config, input_shape, **kwargs):\n",
    "        super(AutoEncoder, self).__init__(**kwargs)\n",
    "        self.config = load_config(config)\n",
    "        self.audio_shape = input_shape\n",
    "\n",
    "        self.act_fn = keras.layers.LeakyReLU()\n",
    "        self.kernel_size = self.config['kernel_size']\n",
    "        \n",
    "        self.embedding_table = _get_embedding_table()\n",
    "\n",
    "        self.conv = [\n",
    "            Conv2D(filters=32, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None,\n",
    "                   input_shape=input_shape),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=64, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=128, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=256, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            Conv2D(filters=512, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            #             keras.layers.Flatten(),\n",
    "            #             Dense(units=output_size, activation=None),\n",
    "            #             self.act_fn\n",
    "        ]\n",
    "\n",
    "        self.dconv = [\n",
    "            # 16\n",
    "            DConv(filters=512, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            # 32\n",
    "            DConv(filters=256, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "            # 64\n",
    "            DConv(filters=128, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "\n",
    "            DConv(filters=64, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            BatchNorm(),\n",
    "            self.act_fn,\n",
    "\n",
    "            DConv(filters=1, kernel_size=self.kernel_size, strides=(2, 2), padding='same', activation=None),\n",
    "            keras.layers.ReLU(max_value=80.0)\n",
    "            #             keras.layers.Activation('sigmoid')\n",
    "            # 128\n",
    "        ]\n",
    "#         self.embed_hidden = Dense(units=self.hidden_size[0] * self.hidden_size[1])\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, **kwargs):\n",
    "        audio, text = inputs\n",
    "        audio = tf.expand_dims(audio, -1)\n",
    "#         text = tf.gather(self.embedding_table, text)\n",
    "        # text embed size: 768\n",
    "\n",
    "        for layer in self.conv:\n",
    "            #             print(inputs.shape)\n",
    "            audio = layer(audio)\n",
    "        for layer in self.dconv:\n",
    "            #             print(inputs.shape)\n",
    "            audio = layer(audio)\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "        return audio\n",
    "    \n",
    "    @property\n",
    "    def hidden_size(self):\n",
    "        return int(self.audio_shape[0] / 2**5), int(self.audio_shape[1] / 2**5)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder(config=config, input_shape=dl.stft_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.hidden_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_audio = tf.data.Dataset.from_generator(partial(dl.train_generator, data='hub'), output_types=tf.float32)\n",
    "dataset_text = tf.data.Dataset.from_generator(partial(dl.train_generator, data='hub', return_text=True), output_types=tf.int32)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_audio, dataset_text))\n",
    "dataset = dataset.shuffle(buffer_size=dl.batch_size * 10).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AutoEncoder.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fbb9f7578d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method AutoEncoder.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fbb9f7578d0>>, which Python reported as:\n",
      "    @tf.function\n",
      "    def call(self, inputs, **kwargs):\n",
      "        audio, text = inputs\n",
      "        audio = tf.expand_dims(audio, -1)\n",
      "#         text = tf.gather(self.embedding_table, text)\n",
      "        # text embed size: 768\n",
      "\n",
      "        for layer in self.conv:\n",
      "            #             print(inputs.shape)\n",
      "            audio = layer(audio)\n",
      "        for layer in self.dconv:\n",
      "            #             print(inputs.shape)\n",
      "            audio = layer(audio)\n",
      "        audio = tf.squeeze(audio, axis=-1)\n",
      "        return audio\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AutoEncoder.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fbb9f7578d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method AutoEncoder.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fbb9f7578d0>>, which Python reported as:\n",
      "    @tf.function\n",
      "    def call(self, inputs, **kwargs):\n",
      "        audio, text = inputs\n",
      "        audio = tf.expand_dims(audio, -1)\n",
      "#         text = tf.gather(self.embedding_table, text)\n",
      "        # text embed size: 768\n",
      "\n",
      "        for layer in self.conv:\n",
      "            #             print(inputs.shape)\n",
      "            audio = layer(audio)\n",
      "        for layer in self.dconv:\n",
      "            #             print(inputs.shape)\n",
      "            audio = layer(audio)\n",
      "        audio = tf.squeeze(audio, axis=-1)\n",
      "        return audio\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method AutoEncoder.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fbb9f7578d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method AutoEncoder.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fbb9f7578d0>>, which Python reported as:\n",
      "    @tf.function\n",
      "    def call(self, inputs, **kwargs):\n",
      "        audio, text = inputs\n",
      "        audio = tf.expand_dims(audio, -1)\n",
      "#         text = tf.gather(self.embedding_table, text)\n",
      "        # text embed size: 768\n",
      "\n",
      "        for layer in self.conv:\n",
      "            #             print(inputs.shape)\n",
      "            audio = layer(audio)\n",
      "        for layer in self.dconv:\n",
      "            #             print(inputs.shape)\n",
      "            audio = layer(audio)\n",
      "        audio = tf.squeeze(audio, axis=-1)\n",
      "        return audio\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_5/Conv2D (defined at /home/mhlee/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_call_3090]\n\nFunction call stack:\ncall\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e62299322fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_5/Conv2D (defined at /home/mhlee/miniconda3/envs/jupyter/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_call_3090]\n\nFunction call stack:\ncall\n"
     ]
    }
   ],
   "source": [
    "autoencoder(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/bert_model/bert_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/bert_model'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.data + '/bert_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, dl.data + '/bert_model', max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_manager.latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert/embeddings/token_type_embeddings : [2, 768]\n",
      "bert/embeddings/word_embeddings : [119547, 768]\n",
      "bert/embeddings/LayerNorm/beta : [768]\n",
      "bert/embeddings/position_embeddings : [512, 768]\n",
      "bert/embeddings/LayerNorm/gamma : [768]\n"
     ]
    }
   ],
   "source": [
    "for key, value in ckpt_loader.get_variable_to_shape_map().items():\n",
    "    if 'embeddings' in key:\n",
    "        print(key, ':', value)\n",
    "    # bert/embeddings/word_embeddings 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_table = tf.Variable(tf.zeros([119547, 768]), name='bert/embeddings/word_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_table = ckpt_loader.get_tensor('bert/embeddings/word_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02595074, -0.00617341, -0.00409975, ...,  0.02965234,\n",
       "         0.02417551,  0.01970279],\n",
       "       [ 0.01038065, -0.0136286 ,  0.00672081, ...,  0.01237162,\n",
       "         0.0267217 ,  0.03370738],\n",
       "       [ 0.0220679 , -0.00360613,  0.01932366, ...,  0.0069061 ,\n",
       "         0.026809  ,  0.00498276],\n",
       "       ...,\n",
       "       [ 0.00684139,  0.01885802,  0.02666426, ...,  0.02292391,\n",
       "         0.06465269,  0.04373793],\n",
       "       [ 0.0183579 ,  0.01480132,  0.02434449, ...,  0.03205629,\n",
       "         0.00708906,  0.02039703],\n",
       "       [ 0.02139908,  0.01879423, -0.01343376, ..., -0.00597953,\n",
       "         0.00583893, -0.00586251]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
