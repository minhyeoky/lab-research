{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import librosa\n",
    "import IPython\n",
    "import data_loader\n",
    "import model\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pformat\n",
    "import logging\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from functools import partial\n",
    "keras = tf.keras\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "importlib.reload(data_loader)\n",
    "DataLoader = data_loader.DataLoader\n",
    "load_config = data_loader.load_config\n",
    "logger = data_loader.logger\n",
    "dataset_hub = tf.data.Dataset.from_generator(partial(dl.generator, data_type='hub'), output_types=tf.float32)\n",
    "\n",
    "importlib.reload(model)\n",
    "Generator = model.Generator\n",
    "Discriminator = model.Discriminator\n",
    "\n",
    "config = './config/cycle-gan1.json'\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:DataLoader initializing\n",
      "INFO:root:reading hub data from ../data/KsponSpeech_01\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0094\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0090\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0048\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0016\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0020\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0074\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0093\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0001\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0105\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0052\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0017\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0039\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0076\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0031\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0087\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0082\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0037\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0019\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0067\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0072\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0006\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0117\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0085\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0029\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0083\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0010\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0116\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0056\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0075\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0043\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0119\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0044\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0115\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0071\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0003\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0004\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0011\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0062\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0103\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0005\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0045\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0014\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0108\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0079\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0032\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0057\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0122\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0092\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0120\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0102\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0050\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0081\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0089\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0007\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0038\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0113\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0018\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0088\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0022\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0033\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0068\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0073\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0034\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0099\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0107\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0065\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0041\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0040\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0078\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0021\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0030\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0064\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0100\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0013\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0053\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0104\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0111\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0028\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0091\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0025\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0109\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0098\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0023\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0012\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0042\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0084\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0058\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0110\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0101\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0106\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0024\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0046\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0047\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0063\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0123\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0059\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0054\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0055\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0051\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0015\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0009\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0095\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0002\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0096\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0061\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0069\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0060\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0124\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0121\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0097\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0080\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0035\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0008\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0026\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0027\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0066\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0077\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0112\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0049\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0036\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0070\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0086\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0118\n",
      "DEBUG:root:../data/KsponSpeech_01/KsponSpeech_0114\n",
      "INFO:root:total number of data: 103312\n",
      "INFO:root:reading lab data from ../data/soundAttGAN & ../data/soundAttGAN/koreancorpus_prep.xlsx\n",
      "INFO:root:total number of data: 1000\n",
      "INFO:root:Build Done\n",
      "INFO:root:== Dataloader paramters ==\n",
      "INFO:root:{'batch_size': 32,\n",
      " 'dropout_rate': 0.5,\n",
      " 'epochs': 100,\n",
      " 'fmax': 8000,\n",
      " 'hop_length': 250,\n",
      " 'kernel_size': 4,\n",
      " 'learning_rate': 0.0002,\n",
      " 'max_sec': 2,\n",
      " 'n_fft': 510,\n",
      " 'n_max': 10,\n",
      " 'n_valid': 0,\n",
      " 'top_db': 80.0,\n",
      " 'win_length': 510,\n",
      " 'window': 'hann'}\n",
      "INFO:root:== Number of dataset == \n",
      "INFO:root:= HUB: 10\n",
      "INFO:root:= LAB: 10\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(config=config, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dl.generator(data_type='hub'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 128)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_hub, dataset_hub)).batch(1)\n",
    "\n",
    "example = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = Discriminator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 128, 2)\n",
      "(1, 128, 64, 32)\n",
      "(1, 128, 64, 32)\n",
      "(1, 128, 64, 32)\n",
      "(1, 64, 32, 64)\n",
      "(1, 64, 32, 64)\n",
      "(1, 64, 32, 64)\n",
      "(1, 32, 16, 128)\n",
      "(1, 32, 16, 128)\n",
      "(1, 32, 16, 128)\n",
      "(1, 34, 18, 128)\n",
      "(1, 31, 15, 256)\n",
      "(1, 31, 15, 256)\n",
      "(1, 31, 15, 256)\n",
      "(1, 33, 17, 256)\n",
      "(1, 30, 14, 1)\n",
      "(1, 30, 14, 1)\n",
      "(1, 256, 128, 2)\n",
      "(1, 128, 64, 32)\n",
      "(1, 128, 64, 32)\n",
      "(1, 128, 64, 32)\n",
      "(1, 64, 32, 64)\n",
      "(1, 64, 32, 64)\n",
      "(1, 64, 32, 64)\n",
      "(1, 32, 16, 128)\n",
      "(1, 32, 16, 128)\n",
      "(1, 32, 16, 128)\n",
      "(1, 34, 18, 128)\n",
      "(1, 31, 15, 256)\n",
      "(1, 31, 15, 256)\n",
      "(1, 31, 15, 256)\n",
      "(1, 33, 17, 256)\n",
      "(1, 30, 14, 1)\n",
      "(1, 30, 14, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2796, shape=(1, 30, 14, 1), dtype=float32, numpy=\n",
       "array([[[[0.4867147 ],\n",
       "         [0.5111776 ],\n",
       "         [0.474577  ],\n",
       "         [0.4996539 ],\n",
       "         [0.49738216],\n",
       "         [0.49410465],\n",
       "         [0.42627048],\n",
       "         [0.5395176 ],\n",
       "         [0.5392447 ],\n",
       "         [0.40168244],\n",
       "         [0.48640516],\n",
       "         [0.50526345],\n",
       "         [0.4651153 ],\n",
       "         [0.48953396]],\n",
       "\n",
       "        [[0.47997722],\n",
       "         [0.49729756],\n",
       "         [0.46812487],\n",
       "         [0.47359753],\n",
       "         [0.4859334 ],\n",
       "         [0.5248797 ],\n",
       "         [0.42631713],\n",
       "         [0.46613652],\n",
       "         [0.4735174 ],\n",
       "         [0.4072634 ],\n",
       "         [0.44917947],\n",
       "         [0.41077825],\n",
       "         [0.44018513],\n",
       "         [0.4765885 ]],\n",
       "\n",
       "        [[0.4871034 ],\n",
       "         [0.5145792 ],\n",
       "         [0.4626422 ],\n",
       "         [0.4532171 ],\n",
       "         [0.48396453],\n",
       "         [0.47001335],\n",
       "         [0.44230366],\n",
       "         [0.48776457],\n",
       "         [0.4334953 ],\n",
       "         [0.35282815],\n",
       "         [0.4117822 ],\n",
       "         [0.47077075],\n",
       "         [0.45568344],\n",
       "         [0.45825237]],\n",
       "\n",
       "        [[0.4862612 ],\n",
       "         [0.49335992],\n",
       "         [0.4470475 ],\n",
       "         [0.45418304],\n",
       "         [0.4760462 ],\n",
       "         [0.4444251 ],\n",
       "         [0.45996845],\n",
       "         [0.51225495],\n",
       "         [0.4412533 ],\n",
       "         [0.4394296 ],\n",
       "         [0.43284824],\n",
       "         [0.5049485 ],\n",
       "         [0.46240368],\n",
       "         [0.47191963]],\n",
       "\n",
       "        [[0.4939947 ],\n",
       "         [0.49744752],\n",
       "         [0.46832567],\n",
       "         [0.49211806],\n",
       "         [0.48449123],\n",
       "         [0.48320854],\n",
       "         [0.46012685],\n",
       "         [0.51788783],\n",
       "         [0.46059233],\n",
       "         [0.4915734 ],\n",
       "         [0.46607304],\n",
       "         [0.46161208],\n",
       "         [0.48095155],\n",
       "         [0.48860237]],\n",
       "\n",
       "        [[0.49749944],\n",
       "         [0.49874964],\n",
       "         [0.48441714],\n",
       "         [0.49408737],\n",
       "         [0.5015934 ],\n",
       "         [0.46853396],\n",
       "         [0.4897699 ],\n",
       "         [0.4985685 ],\n",
       "         [0.48417795],\n",
       "         [0.4855362 ],\n",
       "         [0.4697809 ],\n",
       "         [0.49793988],\n",
       "         [0.49440134],\n",
       "         [0.49631068]],\n",
       "\n",
       "        [[0.50100166],\n",
       "         [0.4995348 ],\n",
       "         [0.49451232],\n",
       "         [0.49548063],\n",
       "         [0.5017774 ],\n",
       "         [0.4873079 ],\n",
       "         [0.49566132],\n",
       "         [0.4981787 ],\n",
       "         [0.4914584 ],\n",
       "         [0.5005667 ],\n",
       "         [0.47636113],\n",
       "         [0.4897897 ],\n",
       "         [0.49561226],\n",
       "         [0.49666864]],\n",
       "\n",
       "        [[0.49928993],\n",
       "         [0.50659746],\n",
       "         [0.5003984 ],\n",
       "         [0.49674535],\n",
       "         [0.49986795],\n",
       "         [0.4928068 ],\n",
       "         [0.4935792 ],\n",
       "         [0.49590468],\n",
       "         [0.5022797 ],\n",
       "         [0.5093119 ],\n",
       "         [0.49112904],\n",
       "         [0.49183708],\n",
       "         [0.4979283 ],\n",
       "         [0.49801958]],\n",
       "\n",
       "        [[0.5030077 ],\n",
       "         [0.5071832 ],\n",
       "         [0.49807346],\n",
       "         [0.4939817 ],\n",
       "         [0.49806508],\n",
       "         [0.4938803 ],\n",
       "         [0.49462378],\n",
       "         [0.50143665],\n",
       "         [0.50156647],\n",
       "         [0.50297976],\n",
       "         [0.49552533],\n",
       "         [0.4956248 ],\n",
       "         [0.49651152],\n",
       "         [0.4968755 ]],\n",
       "\n",
       "        [[0.50443786],\n",
       "         [0.4995511 ],\n",
       "         [0.49852592],\n",
       "         [0.49454626],\n",
       "         [0.49653223],\n",
       "         [0.49245566],\n",
       "         [0.4964057 ],\n",
       "         [0.5018476 ],\n",
       "         [0.4982589 ],\n",
       "         [0.5007467 ],\n",
       "         [0.49678388],\n",
       "         [0.49596718],\n",
       "         [0.49708548],\n",
       "         [0.49744967]],\n",
       "\n",
       "        [[0.50069773],\n",
       "         [0.5116056 ],\n",
       "         [0.49466497],\n",
       "         [0.49712262],\n",
       "         [0.49594107],\n",
       "         [0.49063322],\n",
       "         [0.49854076],\n",
       "         [0.4989537 ],\n",
       "         [0.49786347],\n",
       "         [0.49742988],\n",
       "         [0.49705836],\n",
       "         [0.49833867],\n",
       "         [0.49852931],\n",
       "         [0.4972918 ]],\n",
       "\n",
       "        [[0.49772698],\n",
       "         [0.504182  ],\n",
       "         [0.4944466 ],\n",
       "         [0.5001039 ],\n",
       "         [0.49690396],\n",
       "         [0.49424532],\n",
       "         [0.499397  ],\n",
       "         [0.50345325],\n",
       "         [0.49830112],\n",
       "         [0.497458  ],\n",
       "         [0.4963008 ],\n",
       "         [0.4993188 ],\n",
       "         [0.496855  ],\n",
       "         [0.4977518 ]],\n",
       "\n",
       "        [[0.500168  ],\n",
       "         [0.49863753],\n",
       "         [0.49536303],\n",
       "         [0.49767837],\n",
       "         [0.500382  ],\n",
       "         [0.49582994],\n",
       "         [0.4970495 ],\n",
       "         [0.50511694],\n",
       "         [0.49831668],\n",
       "         [0.4967031 ],\n",
       "         [0.49848235],\n",
       "         [0.4971173 ],\n",
       "         [0.4958848 ],\n",
       "         [0.49836716]],\n",
       "\n",
       "        [[0.50171006],\n",
       "         [0.50165635],\n",
       "         [0.49571675],\n",
       "         [0.49721712],\n",
       "         [0.49836874],\n",
       "         [0.4961847 ],\n",
       "         [0.49805495],\n",
       "         [0.50237894],\n",
       "         [0.49790958],\n",
       "         [0.49803033],\n",
       "         [0.49854484],\n",
       "         [0.495405  ],\n",
       "         [0.49666655],\n",
       "         [0.4981503 ]],\n",
       "\n",
       "        [[0.5016704 ],\n",
       "         [0.5017037 ],\n",
       "         [0.5019583 ],\n",
       "         [0.49839672],\n",
       "         [0.499436  ],\n",
       "         [0.49731594],\n",
       "         [0.49658033],\n",
       "         [0.50262064],\n",
       "         [0.49804845],\n",
       "         [0.49616972],\n",
       "         [0.5002006 ],\n",
       "         [0.4986623 ],\n",
       "         [0.49647403],\n",
       "         [0.4982876 ]],\n",
       "\n",
       "        [[0.50154966],\n",
       "         [0.5009849 ],\n",
       "         [0.49896666],\n",
       "         [0.49825016],\n",
       "         [0.5012963 ],\n",
       "         [0.49311832],\n",
       "         [0.498819  ],\n",
       "         [0.5014768 ],\n",
       "         [0.49703088],\n",
       "         [0.4979715 ],\n",
       "         [0.5004116 ],\n",
       "         [0.49557987],\n",
       "         [0.49626416],\n",
       "         [0.49873635]],\n",
       "\n",
       "        [[0.501649  ],\n",
       "         [0.5002453 ],\n",
       "         [0.49882188],\n",
       "         [0.4974845 ],\n",
       "         [0.49891353],\n",
       "         [0.49580348],\n",
       "         [0.499031  ],\n",
       "         [0.50075847],\n",
       "         [0.49637964],\n",
       "         [0.49851224],\n",
       "         [0.50032103],\n",
       "         [0.49728203],\n",
       "         [0.49558452],\n",
       "         [0.49898887]],\n",
       "\n",
       "        [[0.50006974],\n",
       "         [0.4995483 ],\n",
       "         [0.49860823],\n",
       "         [0.49937004],\n",
       "         [0.49988484],\n",
       "         [0.49745598],\n",
       "         [0.49940142],\n",
       "         [0.49965972],\n",
       "         [0.49939686],\n",
       "         [0.49833432],\n",
       "         [0.49866748],\n",
       "         [0.49738982],\n",
       "         [0.49689654],\n",
       "         [0.4982953 ]],\n",
       "\n",
       "        [[0.5016744 ],\n",
       "         [0.5005193 ],\n",
       "         [0.49952188],\n",
       "         [0.4988101 ],\n",
       "         [0.49990347],\n",
       "         [0.49575835],\n",
       "         [0.49889976],\n",
       "         [0.5009368 ],\n",
       "         [0.49658486],\n",
       "         [0.49945402],\n",
       "         [0.49907893],\n",
       "         [0.49788696],\n",
       "         [0.49637827],\n",
       "         [0.498926  ]],\n",
       "\n",
       "        [[0.5014897 ],\n",
       "         [0.5003887 ],\n",
       "         [0.49984962],\n",
       "         [0.49886578],\n",
       "         [0.49914458],\n",
       "         [0.49762666],\n",
       "         [0.4994015 ],\n",
       "         [0.5014243 ],\n",
       "         [0.49910754],\n",
       "         [0.4990594 ],\n",
       "         [0.4969471 ],\n",
       "         [0.4974367 ],\n",
       "         [0.49727646],\n",
       "         [0.49897164]],\n",
       "\n",
       "        [[0.50058514],\n",
       "         [0.50101614],\n",
       "         [0.49908027],\n",
       "         [0.49965325],\n",
       "         [0.49997333],\n",
       "         [0.49833435],\n",
       "         [0.49924096],\n",
       "         [0.50270957],\n",
       "         [0.49808893],\n",
       "         [0.49788246],\n",
       "         [0.49810693],\n",
       "         [0.4979361 ],\n",
       "         [0.49762326],\n",
       "         [0.49891043]],\n",
       "\n",
       "        [[0.5010333 ],\n",
       "         [0.5013965 ],\n",
       "         [0.498958  ],\n",
       "         [0.4984773 ],\n",
       "         [0.4992424 ],\n",
       "         [0.4977272 ],\n",
       "         [0.49889338],\n",
       "         [0.50155765],\n",
       "         [0.50064117],\n",
       "         [0.49813128],\n",
       "         [0.49859723],\n",
       "         [0.4989525 ],\n",
       "         [0.4976648 ],\n",
       "         [0.49902588]],\n",
       "\n",
       "        [[0.5004471 ],\n",
       "         [0.50067097],\n",
       "         [0.5000819 ],\n",
       "         [0.499547  ],\n",
       "         [0.4988732 ],\n",
       "         [0.4994208 ],\n",
       "         [0.5001378 ],\n",
       "         [0.5023195 ],\n",
       "         [0.4999053 ],\n",
       "         [0.49796218],\n",
       "         [0.49927798],\n",
       "         [0.49858132],\n",
       "         [0.4985401 ],\n",
       "         [0.49940285]],\n",
       "\n",
       "        [[0.50034094],\n",
       "         [0.50225395],\n",
       "         [0.49957496],\n",
       "         [0.49931395],\n",
       "         [0.4989574 ],\n",
       "         [0.49851975],\n",
       "         [0.49827   ],\n",
       "         [0.5026016 ],\n",
       "         [0.4994418 ],\n",
       "         [0.49751157],\n",
       "         [0.500581  ],\n",
       "         [0.4989596 ],\n",
       "         [0.4979779 ],\n",
       "         [0.49933493]],\n",
       "\n",
       "        [[0.5004325 ],\n",
       "         [0.50120467],\n",
       "         [0.4997297 ],\n",
       "         [0.49979562],\n",
       "         [0.49922708],\n",
       "         [0.49822143],\n",
       "         [0.4991774 ],\n",
       "         [0.5016321 ],\n",
       "         [0.49795112],\n",
       "         [0.49765027],\n",
       "         [0.49965054],\n",
       "         [0.4985942 ],\n",
       "         [0.49824846],\n",
       "         [0.4991866 ]],\n",
       "\n",
       "        [[0.50091594],\n",
       "         [0.50142926],\n",
       "         [0.4976466 ],\n",
       "         [0.4997825 ],\n",
       "         [0.5003207 ],\n",
       "         [0.49748576],\n",
       "         [0.49868128],\n",
       "         [0.50158054],\n",
       "         [0.49895084],\n",
       "         [0.49675852],\n",
       "         [0.49862042],\n",
       "         [0.49828026],\n",
       "         [0.4985999 ],\n",
       "         [0.49958205]],\n",
       "\n",
       "        [[0.50022924],\n",
       "         [0.50170845],\n",
       "         [0.49892607],\n",
       "         [0.49888387],\n",
       "         [0.4990482 ],\n",
       "         [0.49861142],\n",
       "         [0.49895385],\n",
       "         [0.5021088 ],\n",
       "         [0.49970868],\n",
       "         [0.49849054],\n",
       "         [0.49857926],\n",
       "         [0.49910504],\n",
       "         [0.49884513],\n",
       "         [0.49976134]],\n",
       "\n",
       "        [[0.4998751 ],\n",
       "         [0.5003743 ],\n",
       "         [0.49892804],\n",
       "         [0.5000112 ],\n",
       "         [0.50077075],\n",
       "         [0.4970121 ],\n",
       "         [0.4981096 ],\n",
       "         [0.5022906 ],\n",
       "         [0.50003654],\n",
       "         [0.49855393],\n",
       "         [0.49818894],\n",
       "         [0.49807614],\n",
       "         [0.49895087],\n",
       "         [0.4997819 ]],\n",
       "\n",
       "        [[0.5004514 ],\n",
       "         [0.5005084 ],\n",
       "         [0.50021166],\n",
       "         [0.50002766],\n",
       "         [0.5006695 ],\n",
       "         [0.4983851 ],\n",
       "         [0.49919757],\n",
       "         [0.5010772 ],\n",
       "         [0.49869785],\n",
       "         [0.49863857],\n",
       "         [0.49926075],\n",
       "         [0.4990589 ],\n",
       "         [0.49919996],\n",
       "         [0.49987563]],\n",
       "\n",
       "        [[0.5003113 ],\n",
       "         [0.50006425],\n",
       "         [0.4997504 ],\n",
       "         [0.5004575 ],\n",
       "         [0.49979708],\n",
       "         [0.4989029 ],\n",
       "         [0.49897942],\n",
       "         [0.49986538],\n",
       "         [0.49774554],\n",
       "         [0.5000439 ],\n",
       "         [0.49936995],\n",
       "         [0.49951357],\n",
       "         [0.49933475],\n",
       "         [0.49980024]]]], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "leaky_re_lu_4 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           multiple                  1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           multiple                  32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           multiple                  131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           multiple                  524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           multiple                  4097      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    multiple                  0         \n",
      "=================================================================\n",
      "Total params: 695,649\n",
      "Trainable params: 694,689\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5003, shape=(1, 256, 128), dtype=float32, numpy=\n",
       "array([[[1.65609399e-05, 6.91431487e-05, 1.17503136e-04, ...,\n",
       "         1.27714084e-04, 3.39420330e-06, 3.04029109e-05],\n",
       "        [0.00000000e+00, 2.56742205e-05, 0.00000000e+00, ...,\n",
       "         2.46173859e-05, 1.30864923e-04, 7.38351446e-05],\n",
       "        [0.00000000e+00, 2.04669806e-04, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.11593724e-04, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 1.04835171e-05, 0.00000000e+00, ...,\n",
       "         4.96782832e-06, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 8.63494733e-06, 0.00000000e+00],\n",
       "        [0.00000000e+00, 6.78107483e-07, 0.00000000e+00, ...,\n",
       "         3.05893059e-06, 7.55028793e-07, 8.02763509e-07]]], dtype=float32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "leaky_re_lu_6 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           multiple                  544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           multiple                  32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           multiple                  131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           multiple                  524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           multiple                  2097664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr multiple                  4194816   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr multiple                  2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr multiple                  524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr multiple                  131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr multiple                  1025      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,743,393\n",
      "Trainable params: 9,739,489\n",
      "Non-trainable params: 3,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
